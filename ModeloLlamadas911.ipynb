{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llamadas 911 desde el primer semestre del 2019 hasta el primer semestre del 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importar librerías\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Embedding, Dropout, BatchNormalization, Bidirectional\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo './Datos/llamadas_911_combinado.csv' ya existe. No se realizará la combinación.\n"
     ]
    }
   ],
   "source": [
    "### Combinación de múltiples archivos CSV en uno solo\n",
    "\n",
    "# Ruta a la carpeta donde están los archivos CSV\n",
    "ruta_archivos = './Datos/'\n",
    "\n",
    "# Nombre del archivo combinado\n",
    "archivo_combinado = './Datos/llamadas_911_combinado.csv'\n",
    "\n",
    "# Verificar si el archivo combinado ya existe\n",
    "if os.path.exists(archivo_combinado):\n",
    "    print(f\"El archivo '{archivo_combinado}' ya existe. No se realizará la combinación.\")\n",
    "else:\n",
    "    # Especifica el patrón de los archivos CSV\n",
    "    archivo_csv = glob.glob(ruta_archivos + 'llamadas_911_*.csv')\n",
    "\n",
    "    # Lista para almacenar tamaños de cada archivo\n",
    "    tamanos_individuales = {}\n",
    "\n",
    "    # Leer cada archivo, manejar errores de codificación y contar filas\n",
    "    dataframes = []\n",
    "    for archivo in archivo_csv:\n",
    "        nombre_archivo = archivo.split('/')[-1]\n",
    "        try:\n",
    "            df = pd.read_csv(archivo, encoding='ISO-8859-1')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(archivo, encoding='cp1252')\n",
    "        dataframes.append(df)\n",
    "        tamanos_individuales[nombre_archivo] = df.shape[0]\n",
    "\n",
    "    # Combinar todos los DataFrames en uno solo\n",
    "    df_combinado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    # Guardar el DataFrame combinado en un archivo CSV\n",
    "    df_combinado.to_csv(archivo_combinado, index=False)\n",
    "\n",
    "    # Calcular la suma de los tamaños individuales\n",
    "    suma_tamanos_individuales = sum(tamanos_individuales.values())\n",
    "    print(f\"Se combinó un total de {suma_tamanos_individuales} filas en '{archivo_combinado}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Primer análisis del DataFrame combinado\n",
    "\n",
    "# Abrir el archivo CSV combinado\n",
    "df_llamadas = pd.read_csv('./Datos/llamadas_911_combinado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Columnas del DataFrame\n",
    "# print(df_llamadas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorías de incidentes reportados:\n",
      "['Medicos' 'Denuncia' 'Danos' 'Servicios' 'Robo' 'Disturbio' 'Incendio'\n",
      " 'Agresion' 'Danos por fenomeno natural o tercero'\n",
      " 'Privacion de la libertad' 'Denuncia de hechos' 'Amenaza' 'Lesionado'\n",
      " 'Derrame o fuga' 'Contra la salud' 'Administrativas'\n",
      " 'Detencion ciudadana' 'Cadaver' 'Abandono' 'Explosion' 'Abandono '\n",
      " 'Sismo' 'Accidente' 'Electorales' 'Intento de suicidio' nan\n",
      " 'Persona extraviada en zona boscosa']\n"
     ]
    }
   ],
   "source": [
    "# # Regresar los valores únicos de las columnas 'categoria_incidente_c4'\n",
    "# categorias_incidente = df_llamadas['categoria_incidente_c4'].unique()\n",
    "# print(\"\\nCategorías de incidentes reportados:\")\n",
    "# print(categorias_incidente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regresar los valores únicos de las columnas 'codigo_cierre'\n",
    "# categorias_incidente = df_llamadas['anio_creacion'].unique()\n",
    "# print(\"\\nCategorías de cierres:\")\n",
    "# print(categorias_incidente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ajuste para remover diciembre 2020\n",
    "df_llamadas = df_llamadas[~((df_llamadas['anio_creacion'] == 2020) & (df_llamadas['mes_creacion'] == 'Diciembre'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Asegúrate de que la columna de fecha esté en formato datetime\n",
    "# df_llamadas['fecha_cierre'] = pd.to_datetime(df_llamadas['fecha_cierre'], errors='coerce')\n",
    "\n",
    "# # Crear una columna de año-mes para el conteo\n",
    "# df_llamadas['anio_mes'] = df_llamadas['fecha_cierre'].dt.to_period('M')\n",
    "\n",
    "# # Contar llamadas por año-mes\n",
    "# conteo_mensual = df_llamadas.groupby('anio_mes').size()\n",
    "\n",
    "# # Rellenar meses faltantes con 0\n",
    "# conteo_mensual = conteo_mensual.reindex(pd.period_range(start=df_llamadas['anio_mes'].min(),\n",
    "#                                                         end=df_llamadas['anio_mes'].max(), freq='M'), fill_value=0)\n",
    "\n",
    "# # Convertir a DataFrame para visualización\n",
    "# conteo_mensual_df = conteo_mensual.reset_index()\n",
    "# conteo_mensual_df.columns = ['Mes', 'Total_Llamadas']\n",
    "\n",
    "# # Mostrar el DataFrame con el conteo mensual incluyendo meses con 0\n",
    "# conteo_mensual_df\n",
    "\n",
    "# # Graficar el conteo mensual de llamadas\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(conteo_mensual_df['Mes'].astype(str), conteo_mensual_df['Total_Llamadas'], marker='o')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.xlabel('Mes')\n",
    "# plt.ylabel('Total de Llamadas')\n",
    "# plt.title('Total de Llamadas al 911 por Mes')\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Verificar cantidad de NaNs en el DataFrame\n",
    "# print(\"\\nCantidad de valores nulos por columna:\")\n",
    "# print(df_llamadas.isnull().sum())\n",
    "\n",
    "# # # Ver qué características tienen las filas donde 'categoria_incidente_c4' es nulo en contraste con el total de filas\n",
    "# # print(\"\\nFilas con 'categoria_incidente_c4' nulo:\")\n",
    "# # print(df_llamadas[df_llamadas['categoria_incidente_c4'].isnull()])\n",
    "\n",
    "# # Contar cuántas filas tienen 'categoria_incidente_c4'\n",
    "# conteo_categoria_incidente = df_llamadas['categoria_incidente_c4'].count()\n",
    "# total_filas = df_llamadas.shape[0]\n",
    "# print(f\"\\nPorcentaje de filas con 'categoria_incidente_c4' no nulo: {conteo_categoria_incidente / total_filas:.2%}\")\n",
    "\n",
    "# # Eliminar filas con 'categoria_incidente_c4' nulo\n",
    "# df_llamadas = df_llamadas.dropna(subset=['categoria_incidente_c4'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Diseño del Modelo\n",
    "### Entrada Geográfica (CNN):\n",
    "\n",
    "- Convertir las coordenadas en cuadrículas para capturar patrones espaciales relacionados con los tipos de cierre (codigo_cierre). \\\n",
    "- La CNN detectará patrones de áreas geográficas con alta frecuencia de llamadas reales, falsas, etc.\n",
    "\n",
    "### Entrada Temporal (LSTM):\n",
    "\n",
    "- Usar datos como el día del año, la hora y otras características temporales para capturar estacionalidad y patrones temporales.\n",
    "- La LSTM identificará tendencias en las llamadas relacionadas con temporadas o días específicos.\n",
    "\n",
    "### Concatenación y Clasificación:\n",
    "\n",
    "- Combinar las salidas de CNN y LSTM.\n",
    "- Añadir una capa densa para predecir la probabilidad de cada clase de codigo_cierre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Datos Espaciales\n",
    "El modelo CNN espera una entrada en forma de matriz (10x10 en este caso). Sigue estos pasos para transformar las coordenadas en cuadrículas: \\\n",
    "Paso 1: Normalizar las coordenadas (latitud, longitud) para que estén en un rango uniforme. \\\n",
    "Paso 2: Dividir las coordenadas en una cuadrícula (e.g., 10x10). \\\n",
    "Paso 3: Crear una matriz de frecuencia para cada cuadrícula (representando la intensidad de llamadas en cada región).\n",
    "\n",
    "#### 1.2 Datos Temporales (fecha_creacion, hora_creacion)\n",
    "El modelo LSTM espera datos en formato de secuencia temporal. Aquí transformaremos los datos:\n",
    "\n",
    "- Paso 1: Extraer características temporales relevantes como el día de la semana, hora, mes, etc.\n",
    "- Paso 2: Agrupar llamadas en secuencias de tiempo (e.g., 24 horas).\n",
    "\n",
    "#### 1.3 Categoría del Incidente (categoria_incidente_c4)\n",
    "La columna categoria_incidente_c4 necesita ser convertida en un índice o embedding:\n",
    "\n",
    "- Paso 1: Convertir las categorías en índices únicos.\n",
    "- Paso 2: Pasar estos índices al modelo como entrada para embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Contar la cantidad de ocurrencias de cada clase en 'codigo_cierre'\n",
    "# clase_counts = df_llamadas['codigo_cierre'].value_counts()\n",
    "\n",
    "# # Mostrar la distribución de las clases\n",
    "# print(clase_counts)\n",
    "\n",
    "# # Visualizar el balance de las clases en un gráfico de barras\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# clase_counts.plot(kind='bar')\n",
    "# plt.xlabel('Clase de Cierre')\n",
    "# plt.ylabel('Número de Llamadas')\n",
    "# plt.title('Distribución de las Clases en \"codigo_cierre\"')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Spatial_Temporal_Model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input_CNN (InputLayer)         [(None, 10, 10, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 10, 10, 8)    80          ['Input_CNN[0][0]']              \n",
      "                                                                                                  \n",
      " Input_Category (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooling2D  (None, 5, 5, 8)     0           ['conv2d_16[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Input_LSTM (InputLayer)        [(None, 24, 5)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding_16 (Embedding)       (None, 1, 8)         216         ['Input_Category[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_32 (Flatten)           (None, 200)          0           ['max_pooling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)                 (None, 16)           1408        ['Input_LSTM[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_33 (Flatten)           (None, 8)            0           ['embedding_16[0][0]']           \n",
      "                                                                                                  \n",
      " Concatenate (Concatenate)      (None, 224)          0           ['flatten_32[0][0]',             \n",
      "                                                                  'lstm_16[0][0]',                \n",
      "                                                                  'flatten_33[0][0]']             \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 16)           3600        ['Concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 16)           0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " Output (Dense)                 (None, 5)            85          ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,389\n",
      "Trainable params: 5,389\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "4053/4053 [==============================] - 22s 5ms/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4053/4053 [==============================] - 20s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4053/4053 [==============================] - 23s 6ms/step - loss: 8.3297e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4053/4053 [==============================] - 26s 6ms/step - loss: 2.0919e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4053/4053 [==============================] - 24s 6ms/step - loss: 7.5418e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "4053/4053 [==============================] - 23s 6ms/step - loss: 3.2848e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "4053/4053 [==============================] - 26s 6ms/step - loss: 1.4593e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "4053/4053 [==============================] - 22s 6ms/step - loss: 7.5697e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 9/10\n",
      "4053/4053 [==============================] - 22s 6ms/step - loss: 4.7869e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 10/10\n",
      "4053/4053 [==============================] - 24s 6ms/step - loss: 3.1169e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, concatenate, Embedding, Dropout, BatchNormalization, Bidirectional\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ---- 1. Procesar Datos Espaciales (latitud, longitud) ----\n",
    "\n",
    "# Eliminar columnas no necesarias para reducir uso de memoria\n",
    "columnas_utilizadas = ['latitud', 'longitud', 'fecha_creacion', 'hora_creacion', 'categoria_incidente_c4', 'codigo_cierre']\n",
    "df_llamadas = df_llamadas[columnas_utilizadas]\n",
    "\n",
    "# Normalizar coordenadas\n",
    "df_llamadas['lat_norm'] = (df_llamadas['latitud'] - df_llamadas['latitud'].min()) / (df_llamadas['latitud'].max() - df_llamadas['latitud'].min())\n",
    "df_llamadas['lon_norm'] = (df_llamadas['longitud'] - df_llamadas['longitud'].min()) / (df_llamadas['longitud'].max() - df_llamadas['longitud'].min())\n",
    "\n",
    "# Crear cuadrículas\n",
    "grid_size = 10\n",
    "df_llamadas['lat_bin'] = (df_llamadas['lat_norm'] * (grid_size - 1)).astype(int)\n",
    "df_llamadas['lon_bin'] = (df_llamadas['lon_norm'] * (grid_size - 1)).astype(int)\n",
    "\n",
    "# Crear matriz para CNN\n",
    "X_cnn = np.zeros((len(df_llamadas), grid_size, grid_size, 1), dtype=np.float32)\n",
    "for idx, row in df_llamadas.iterrows():\n",
    "    if idx < len(X_cnn) and 0 <= row['lat_bin'] < grid_size and 0 <= row['lon_bin'] < grid_size:\n",
    "        X_cnn[idx, row['lat_bin'], row['lon_bin'], 0] = 1\n",
    "\n",
    "# ---- 2. Procesar Datos Temporales (fecha_creacion, hora_creacion) ----\n",
    "\n",
    "# Definir la longitud de la secuencia\n",
    "sequence_length = 24\n",
    "\n",
    "# Convertir fecha a datetime, forzando la conversión y filtrando fechas inválidas\n",
    "df_llamadas['fecha_creacion'] = pd.to_datetime(df_llamadas['fecha_creacion'], errors='coerce')\n",
    "df_llamadas = df_llamadas[df_llamadas['fecha_creacion'].notna()]\n",
    "\n",
    "# Crear características temporales\n",
    "df_llamadas['dia_semana'] = df_llamadas['fecha_creacion'].dt.dayofweek  # 0: Lunes, 6: Domingo\n",
    "\n",
    "# Extraer la hora de 'hora_creacion' en formato HH:MM:SS\n",
    "df_llamadas['hora'] = df_llamadas['hora_creacion'].str.split(':').str[0].astype(int)\n",
    "df_llamadas['mes'] = df_llamadas['fecha_creacion'].dt.month\n",
    "\n",
    "# Normalizar características\n",
    "df_llamadas['hora_norm'] = df_llamadas['hora'] / 23.0\n",
    "df_llamadas['dia_semana_norm'] = df_llamadas['dia_semana'] / 6.0\n",
    "df_llamadas['mes_norm'] = df_llamadas['mes'] / 12.0\n",
    "\n",
    "# Crear secuencias temporales utilizando un enfoque más eficiente, agregando latitud y longitud normalizadas\n",
    "data_temporal = df_llamadas[['hora_norm', 'dia_semana_norm', 'mes_norm', 'lat_norm', 'lon_norm']].values.astype(np.float32)\n",
    "X_lstm = [data_temporal[i:i+sequence_length] for i in range(0, len(data_temporal) - sequence_length, sequence_length)]\n",
    "X_lstm = np.array(X_lstm)\n",
    "\n",
    "# ---- 3. Procesar Categorías (categoria_incidente_c4) ----\n",
    "\n",
    "# Crear mapa de categorías\n",
    "categoria_map = {cat: idx for idx, cat in enumerate(df_llamadas['categoria_incidente_c4'].dropna().unique())}\n",
    "df_llamadas['categoria_idx'] = df_llamadas['categoria_incidente_c4'].map(categoria_map).fillna(0).astype(int)\n",
    "\n",
    "# Preparar entrada para embeddings\n",
    "X_cat = df_llamadas['categoria_idx'].values[:len(X_lstm)]\n",
    "\n",
    "# ---- 4. Procesar Etiquetas (codigo_cierre) ----\n",
    "\n",
    "# Procesar etiquetas multiclase (A, I, N, D, F)\n",
    "categoria_etiqueta_map = {'A': 0, 'I': 1, 'N': 2, 'D': 3, 'F': 4}\n",
    "df_llamadas['codigo_cierre_idx'] = df_llamadas['codigo_cierre'].map(categoria_etiqueta_map).fillna(0).astype(int)\n",
    "y = tf.keras.utils.to_categorical(df_llamadas['codigo_cierre_idx'].values[:len(X_lstm)], num_classes=5)\n",
    "\n",
    "# ---- 5. Ajustar Dimensiones y Entrenamiento del Modelo ----\n",
    "\n",
    "# Ajustar tamaño de X_cnn para que coincida con X_lstm\n",
    "X_cnn = X_cnn[:len(X_lstm)]\n",
    "\n",
    "# ---- 6. Arquitectura del Modelo ----\n",
    "\n",
    "# Entrada geográfica (CNN)\n",
    "input_cnn = Input(shape=(10, 10, 1), name='Input_CNN')\n",
    "cnn = Conv2D(8, (3, 3), activation='relu', padding='same')(input_cnn)\n",
    "cnn = MaxPooling2D((2, 2))(cnn)\n",
    "cnn = Flatten()(cnn)\n",
    "cnn_output = cnn\n",
    "\n",
    "\n",
    "# Entrada temporal (LSTM)\n",
    "input_lstm = Input(shape=(24, 5), name='Input_LSTM')\n",
    "lstm = LSTM(16, activation='tanh', return_sequences=False)(input_lstm)\n",
    "lstm_output = lstm\n",
    "\n",
    "\n",
    "\n",
    "# Embeddings para `categoria_incidente_c4`\n",
    "input_cat = Input(shape=(1,), name='Input_Category')\n",
    "embedding = Embedding(input_dim=len(categoria_map)+1, output_dim=8)(input_cat)\n",
    "embedding = Flatten()(embedding)\n",
    "\n",
    "# Concatenación\n",
    "combined = concatenate([cnn_output, lstm_output, embedding], name='Concatenate')\n",
    "dense = Dense(16, activation='relu')(combined)\n",
    "\n",
    "dense = Dropout(0.3)(dense)\n",
    "output = Dense(5, activation='softmax', name='Output')(dense)  # Salida multiclase (A, I, N, D, F)\n",
    "\n",
    "# Definición del modelo\n",
    "model = Model(inputs=[input_cnn, input_lstm, input_cat], outputs=output, name='Spatial_Temporal_Model')\n",
    "\n",
    "# Compilación\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# ---- 7. Entrenamiento del Modelo ----\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5)\n",
    "history = model.fit(\n",
    "    [X_cnn, X_lstm, X_cat], y,\n",
    "    batch_size=32, epochs=10, validation_split=0.2, callbacks=[reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
